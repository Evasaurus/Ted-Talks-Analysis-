%matplotlib inline
import pandas as pd
import numpy as np
from scipy import stats
import matplotlib.pyplot as plt
import seaborn as sns
import json
from pandas.io.json import json_normalize

#get the first set of data
df = pd.read_csv('C:/Users/dad/Desktop/136//data/kaggle-data/ted_main.csv')
df.columns

#and keep it tidy
df = df[['name', 'title', 'description', 'main_speaker', 'speaker_occupation', 'num_speaker', 'duration', 'event', 'film_date', 'published_date', 'comments', 'tags', 'languages', 'ratings', 'related_talks', 'views', 'url']]

#convert the timestamp
import datetime
df['film_date'] = df['film_date'].apply(lambda x: datetime.datetime.fromtimestamp( int(x)).strftime('%d-%m-%Y'))
df['published_date'] = df['published_date'].apply(lambda x: datetime.datetime.fromtimestamp( int(x)).strftime('%d-%m-%Y'))

#and check that everything looks correct
df.head()

#lets incorporate the secoond dataset in the same way
df2 = pd.read_csv('C:/Users/dad/Desktop/136/data/kaggle-data/transcripts.csv')
df2.head()

df2 = df2[['url', 'transcript']]
df2.head()

#and let's join them!
df3 = pd.merge(left=df,right=df2, how='left', left_on='url', right_on='url')

#double check
df3.head()

#ensuring there are no empty slots before creating a wordcount attribute
df3['transcript'] = df3['transcript'].fillna('')
df3['wc'] = df3['transcript'].apply(lambda x: len(x.split()))

#and make sure the empty slots are gone
print(df3.transcript.isna().sum())
print(df3.transcript.isnull().sum())

#and taking a look at our new attribute
df3['wc'].describe()

#adding another attribute, words per minute
df3['wpm'] = df3['wc']/df3['duration']

#Now we have a merged data frame - lets clean it up much more.
import os
import pandas as pd
import numpy as np
from sklearn.feature_extraction import text
from sklearn.metrics.pairwise import cosine_similarity


df3['title']=df3['url'].map(lambda x:x.split("/")[-1])

def analyzeScripts():
    scripts = getScripts()
    vectorMatrix = generateTFIDMatrix(scripts)
    unigramMatrix = generateUnigramMatrix(vectorMatrix)
    return vectorMatrix, unigramMatrix

def getScripts():
    return df3['transcript'].tolist()

def generateTFIDMatrix(scripts):
    tfidfGenerator = text.TfidfVectorizer(input= scripts, stop_words= "english")
    matrix = tfidfGenerator.fit_transform(scripts)
    return matrix

def generateUnigram(tfidMatrix):
    return cosine_similarity(tfidMatrix)

def getSimilarArticles(articleText):
    allScripts = getScripts()
    allScripts.append(articleText)
    tfdiMatrix = generateTFIDMatrix(allScripts)
    unigram = generateUnigram(tfdiMatrix)
    return ",".join(df3['title'].loc[unigram[-1].argsort()[-5:-1]])


if __name__ == "__main__":
    allScripts = getScripts()
    testText = allScripts.pop(5)
    df3.drop(5, inplace=True)
    #tfidfGenerator = text.TfidfVectorizer(input= allScripts, stop_words= "english")
    #matrix = tfidfGenerator.fit_transform(allScripts)
    #print(matrix.shape)

    #print(generateTFIDMatrix(allScripts).shape)
    #print(generateUnigram(matrix).shape)
    print(getSimilarArticles(testText))

df3['wpm'].describe()

#save this version
df3.to_csv('merged_data.csv', encoding='utf-8')

This is where I am having trouble!!!
import sys
import pandas as pd
import numpy as np
from scipy.sparse import csr_matrix
from sklearn.feature_extraction import text

def getVectors(dataFrame):
    scripts = dataFrame['transcript'].tolist()
    #print(len(scripts))
    #print(dataFrame['transcript'])
    #print(dataFrame.transcript.isnull().sum())
    tfidfGenerator = text.TfidfVectorizer(input= scripts, stop_words= "english")
    matrix = tfidfGenerator.fit_transform(scripts)
    return matrix

def writeFile(fileName, vectors):
    with open(fileName[:-4] + "_vectors.csv", 'w+') as file:
        for row in vectors:
            line = ''
            for num in row:
                line += str(num) + ','
            line = line[:-1]
            line = line + '\n'
            file.write(line)

def main():
    #fileName = sys.argv[0]
    filepath = "C:/Users/dad/Desktop/136/data/kaggle-data/"
    fileName = "merged_data.csv"
    print("Generating TFID vectors...")
    dataFrame = pd.read_csv(filepath + fileName)
    dataFrame = dataFrame['transcript']
    dataFrame = dataFrame[pd.notnull(dataFrame)]
    dataFrame = getVectors(dataFrame)
    writeFile(filepath + fileName, vectors)
    print("Wrote TFIFD data to {}".format(filepath + fileName[:-4] + "_vectors.csv"))

if __name__ == "__main__":
    main()
    

